{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab ACtivity 7 - Artificial Neural Network\n",
    "\n",
    "TP noté, à rendre.\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas\n",
    "import pandas as pd\n",
    "# Sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "# Numpy\n",
    "import numpy as np\n",
    "# Matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# Seaborn\n",
    "import seaborn as sns\n",
    "# pip install tensorflow\n",
    "# Télécharger le code source de TensorFlow pour l'utiliser de façon optimale.\n",
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "# Keras\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Charger les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 10000 entries, 15634602 to 15628319\n",
      "Data columns (total 13 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   Surname          10000 non-null  object \n",
      " 2   CreditScore      10000 non-null  int64  \n",
      " 3   Geography        10000 non-null  object \n",
      " 4   Gender           10000 non-null  object \n",
      " 5   Age              10000 non-null  int64  \n",
      " 6   Tenure           10000 non-null  int64  \n",
      " 7   Balance          10000 non-null  float64\n",
      " 8   NumOfProducts    10000 non-null  int64  \n",
      " 9   HasCrCard        10000 non-null  int64  \n",
      " 10  IsActiveMember   10000 non-null  int64  \n",
      " 11  EstimatedSalary  10000 non-null  float64\n",
      " 12  Exited           10000 non-null  int64  \n",
      "dtypes: float64(2), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('bank_customers.csv', sep=',').set_index('CustomerId')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Inspecter et nettoyer les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            RowNumber   Surname  CreditScore Geography  Gender  Age  Tenure  \\\n",
      "CustomerId                                                                    \n",
      "15634602            1  Hargrave          619    France  Female   42       2   \n",
      "15647311            2      Hill          608     Spain  Female   41       1   \n",
      "15619304            3      Onio          502    France  Female   42       8   \n",
      "15701354            4      Boni          699    France  Female   39       1   \n",
      "15737888            5  Mitchell          850     Spain  Female   43       2   \n",
      "\n",
      "              Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
      "CustomerId                                                        \n",
      "15634602         0.00              1          1               1   \n",
      "15647311     83807.86              1          0               1   \n",
      "15619304    159660.80              3          1               0   \n",
      "15701354         0.00              2          0               0   \n",
      "15737888    125510.82              1          1               1   \n",
      "\n",
      "            EstimatedSalary  Exited  \n",
      "CustomerId                           \n",
      "15634602          101348.88       1  \n",
      "15647311          112542.58       0  \n",
      "15619304          113931.57       1  \n",
      "15701354           93826.63       0  \n",
      "15737888           79084.10       0  \n",
      "RowNumber          0\n",
      "Surname            0\n",
      "CreditScore        0\n",
      "Geography          0\n",
      "Gender             0\n",
      "Age                0\n",
      "Tenure             0\n",
      "Balance            0\n",
      "NumOfProducts      0\n",
      "HasCrCard          0\n",
      "IsActiveMember     0\n",
      "EstimatedSalary    0\n",
      "Exited             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Visualisartion\n",
    "print(df.head())\n",
    "\n",
    "# Vérifier les valeurs manquantes\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression des colonnes inutiles :\n",
    "df.drop(['RowNumber', 'Surname'], axis=1, inplace=True)\n",
    "\n",
    "# Gestion des NaN (aucun NaN)\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Encoder de façon catégoriel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding\n",
    "colonnes_categorielles = ['Gender', 'Geography']\n",
    "df = pd.get_dummies(df, columns=colonnes_categorielles)\n",
    "\n",
    "# Convertir les colonnes résultantes du codage one-hot en int\n",
    "for col in df.columns:\n",
    "    if col.startswith(tuple(colonnes_categorielles)):\n",
    "        df[col] = df[col].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Diviser les données en entrainement et test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Exited', axis=1)  # Supposons que 'Exited' soit la colonne cible\n",
    "y = df['Exited']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. StandarScaler pour standardiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Utiliser keras.models pour initialiser ANN en faisant par couche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiser le ANN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Ajouter la couche d'entrée et la première couche cachée en utilidant la méthode add()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajouter la couche d'entrée et la première couche cachée\n",
    "classifier.add(Dense(units=6, kernel_initializer='uniform', activation='relu', input_dim=X_train.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Ajouter une deuxième couche cachée composée de 6 unités"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajouter une deuxième couche cachée\n",
    "classifier.add(Dense(units=6, kernel_initializer='uniform', activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Ajouter la couche de sortie avec une unité binaire, et ne pas oublier l'activation sigmoïde fonction à utiliser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajouter la couche de sortie\n",
    "classifier.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Configurer le modèle d'apprentissage, via la méthode de comilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiler le ANN\n",
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Ajouster le modèle et appliquer la validation croisée avec une taille de lot de 10. Répéter 50 ou 100 fois (époque = 50 ou 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajuster le ANN à l'ensemble d'entraînement\n",
    "classifier.fit(X_train, y_train, batch_size=10, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Faire des prédictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédire les résultats sur l'ensemble de test\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Evaluer le modèle à l'aide de la matrice de confusion et du rapport de classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice de confusion et rapport de classification\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Prédire si le client avec les informations suivantes quittera la banque ou non : Géographie : France • Pointage de crédit : 600 • Sexe : Homme • Âge : 40 • Ancienneté : 3 • Solde : 60000 • Nombre de produits : 2 • Possède un crédit carte : Oui • Est membre actif : Oui • Salaire estimé : 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple de données client\n",
    "new_customer = [[600, 40, 3, 60000, 2, 1, 1, 50000, 1, 0, 0]]  # Ajouter des variables dummy pour 'Geography' et 'Gender'\n",
    "new_customer = scaler.transform(new_customer)\n",
    "new_prediction = classifier.predict(new_customer)\n",
    "new_prediction = (new_prediction > 0.5)\n",
    "print(new_prediction)  # True pour quitter, False pour rester\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Utiliser des modèles Keras séquentiels dans le cadre du flux de trvail Scikit-Learn via le wrappers trouvés dans la bibliothèque Keras. Suivre les instruction données dans le notebook Python pour comprendre comment utiliser KerasClassifier à partir de keras.wrappers.scikit_learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier():\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(units=6, kernel_initializer='uniform', activation='relu', input_dim=X_train.shape[1]))\n",
    "    classifier.add(Dense(units=6, kernel_initializer='uniform', activation='relu'))\n",
    "    classifier.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "    classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return classifier\n",
    "\n",
    "classifier = KerasClassifier(build_fn=build_classifier, batch_size=10, epochs=100)\n",
    "accuracies = cross_val_score(estimator=classifier, X=X_train, y=y_train, cv=10, n_jobs=-1)\n",
    "mean_accuracy = accuracies.mean()\n",
    "variance = accuracies.std()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.11 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
