{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab ACtivity 7 - Artificial Neural Network\n",
    "\n",
    "TP noté, à rendre.\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'keras' has no attribute '__version__' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 20\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mseaborn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msns\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[39m# pip install tensorflow\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[39m# Télécharger le code source de TensorFlow pour l'utiliser de façon optimale.\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[39m# Tensorflow\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[39m#import tensorflow as tf\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[39m# Keras\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n\u001b[0;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m Dense\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mwrappers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mscikit_learn\u001b[39;00m \u001b[39mimport\u001b[39;00m KerasClassifier\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m__future__\u001b[39;00m \u001b[39mimport\u001b[39;00m absolute_import\n\u001b[1;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m utils\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m activations\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m applications\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\utils\\__init__.py:26\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mlayer_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m get_source_inputs\n\u001b[0;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mlayer_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m print_summary\n\u001b[1;32m---> 26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mvis_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m model_to_dot\n\u001b[0;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mvis_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m plot_model\n\u001b[0;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mnp_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m to_categorical\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\utils\\vis_utils.py:7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m__future__\u001b[39;00m \u001b[39mimport\u001b[39;00m print_function\n\u001b[0;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m Model\n\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mwrappers\u001b[39;00m \u001b[39mimport\u001b[39;00m Wrapper\n\u001b[0;32m     10\u001b[0m \u001b[39m# `pydot` is an optional dependency,\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[39m# see `extras_require` in `setup.py`.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\models.py:10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgeneric_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m has_arg\n\u001b[0;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgeneric_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m to_list\n\u001b[1;32m---> 10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minput_layer\u001b[39;00m \u001b[39mimport\u001b[39;00m Input\n\u001b[0;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minput_layer\u001b[39;00m \u001b[39mimport\u001b[39;00m InputLayer\n\u001b[0;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtraining\u001b[39;00m \u001b[39mimport\u001b[39;00m Model\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\__init__.py:8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbase_layer\u001b[39;00m \u001b[39mimport\u001b[39;00m Layer\n\u001b[0;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mnetwork\u001b[39;00m \u001b[39mimport\u001b[39;00m get_source_inputs\n\u001b[1;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtraining\u001b[39;00m \u001b[39mimport\u001b[39;00m Model\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training.py:14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mnetwork\u001b[39;00m \u001b[39mimport\u001b[39;00m Network\n\u001b[0;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbase_layer\u001b[39;00m \u001b[39mimport\u001b[39;00m Layer\n\u001b[1;32m---> 14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m training_utils\n\u001b[0;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m training_arrays\n\u001b[0;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m training_generator\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training_utils.py:17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m backend \u001b[39mas\u001b[39;00m K\n\u001b[0;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m losses\n\u001b[1;32m---> 17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m metrics \u001b[39mas\u001b[39;00m metrics_module\n\u001b[0;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequence\n\u001b[0;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m generic_utils\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\metrics.py:1850\u001b[0m\n\u001b[0;32m   1848\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m   1849\u001b[0m     \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39m__version__ \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m2.0.0\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m-> 1850\u001b[0m         BaseMeanIoU \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mmetrics\u001b[39m.\u001b[39mMeanIoU\n\u001b[0;32m   1853\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mMeanIoU\u001b[39;00m(BaseMeanIoU):\n\u001b[0;32m   1854\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Computes the mean Intersection-Over-Union metric.\u001b[39;00m\n\u001b[0;32m   1855\u001b[0m \n\u001b[0;32m   1856\u001b[0m \u001b[39m    Mean Intersection-Over-Union is a common evaluation metric for semantic image\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1881\u001b[0m \u001b[39m        dtype: (Optional) data type of the metric result.\u001b[39;00m\n\u001b[0;32m   1882\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\lazy_loader.py:146\u001b[0m, in \u001b[0;36mKerasLazyLoader.__getattr__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m    144\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m(types\u001b[39m.\u001b[39mModuleType, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__getattribute__\u001b[39m(item)\n\u001b[0;32m    145\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_initialized:\n\u001b[1;32m--> 146\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_initialize()\n\u001b[0;32m    147\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_keras_version \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mkeras_3\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    148\u001b[0m   \u001b[39mif\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mv1\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m\n\u001b[0;32m    149\u001b[0m       \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_submodule \u001b[39mand\u001b[39;00m\n\u001b[0;32m    150\u001b[0m       item\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39mcompat.v1.\u001b[39m\u001b[39m\"\u001b[39m)):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\lazy_loader.py:116\u001b[0m, in \u001b[0;36mKerasLazyLoader._initialize\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    114\u001b[0m   \u001b[39mimport\u001b[39;00m \u001b[39mkeras\u001b[39;00m  \u001b[39m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[1;32m--> 116\u001b[0m   \u001b[39mif\u001b[39;00m keras\u001b[39m.\u001b[39;49m__version__\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39m3.\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    117\u001b[0m     \u001b[39m# This is the Keras 3.x case.\u001b[39;00m\n\u001b[0;32m    118\u001b[0m     keras_version \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mkeras_3\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    119\u001b[0m     package_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mkeras._tf_keras.keras\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[1;31mAttributeError\u001b[0m: partially initialized module 'keras' has no attribute '__version__' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "# Pandas\n",
    "import pandas as pd\n",
    "# Sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "# Numpy\n",
    "import numpy as np\n",
    "# Matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# Seaborn\n",
    "import seaborn as sns\n",
    "# pip install tensorflow\n",
    "# Télécharger le code source de TensorFlow pour l'utiliser de façon optimale.\n",
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "# Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Charger les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 10000 entries, 15634602 to 15628319\n",
      "Data columns (total 13 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   Surname          10000 non-null  object \n",
      " 2   CreditScore      10000 non-null  int64  \n",
      " 3   Geography        10000 non-null  object \n",
      " 4   Gender           10000 non-null  object \n",
      " 5   Age              10000 non-null  int64  \n",
      " 6   Tenure           10000 non-null  int64  \n",
      " 7   Balance          10000 non-null  float64\n",
      " 8   NumOfProducts    10000 non-null  int64  \n",
      " 9   HasCrCard        10000 non-null  int64  \n",
      " 10  IsActiveMember   10000 non-null  int64  \n",
      " 11  EstimatedSalary  10000 non-null  float64\n",
      " 12  Exited           10000 non-null  int64  \n",
      "dtypes: float64(2), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('bank_customers.csv', sep=',').set_index('CustomerId')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Inspecter et nettoyer les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            RowNumber   Surname  CreditScore Geography  Gender  Age  Tenure  \\\n",
      "CustomerId                                                                    \n",
      "15634602            1  Hargrave          619    France  Female   42       2   \n",
      "15647311            2      Hill          608     Spain  Female   41       1   \n",
      "15619304            3      Onio          502    France  Female   42       8   \n",
      "15701354            4      Boni          699    France  Female   39       1   \n",
      "15737888            5  Mitchell          850     Spain  Female   43       2   \n",
      "\n",
      "              Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
      "CustomerId                                                        \n",
      "15634602         0.00              1          1               1   \n",
      "15647311     83807.86              1          0               1   \n",
      "15619304    159660.80              3          1               0   \n",
      "15701354         0.00              2          0               0   \n",
      "15737888    125510.82              1          1               1   \n",
      "\n",
      "            EstimatedSalary  Exited  \n",
      "CustomerId                           \n",
      "15634602          101348.88       1  \n",
      "15647311          112542.58       0  \n",
      "15619304          113931.57       1  \n",
      "15701354           93826.63       0  \n",
      "15737888           79084.10       0  \n",
      "RowNumber          0\n",
      "Surname            0\n",
      "CreditScore        0\n",
      "Geography          0\n",
      "Gender             0\n",
      "Age                0\n",
      "Tenure             0\n",
      "Balance            0\n",
      "NumOfProducts      0\n",
      "HasCrCard          0\n",
      "IsActiveMember     0\n",
      "EstimatedSalary    0\n",
      "Exited             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Visualisartion\n",
    "print(df.head())\n",
    "\n",
    "# Vérifier les valeurs manquantes\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression des colonnes inutiles :\n",
    "df.drop(['RowNumber', 'Surname'], axis=1, inplace=True)\n",
    "\n",
    "# Gestion des NaN (aucun NaN)\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Encoder de façon catégoriel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding\n",
    "colonnes_categorielles = ['Gender', 'Geography']\n",
    "df = pd.get_dummies(df, columns=colonnes_categorielles)\n",
    "\n",
    "# Convertir les colonnes résultantes du codage one-hot en int\n",
    "for col in df.columns:\n",
    "    if col.startswith(tuple(colonnes_categorielles)):\n",
    "        df[col] = df[col].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Diviser les données en entrainement et test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Exited', axis=1)  # Supposons que 'Exited' soit la colonne cible\n",
    "y = df['Exited']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. StandarScaler pour standardiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Utiliser keras.models pour initialiser ANN en faisant par couche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiser le ANN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Ajouter la couche d'entrée et la première couche cachée en utilidant la méthode add()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajouter la couche d'entrée et la première couche cachée\n",
    "classifier.add(Dense(units=6, kernel_initializer='uniform', activation='relu', input_dim=X_train.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Ajouter une deuxième couche cachée composée de 6 unités"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajouter une deuxième couche cachée\n",
    "classifier.add(Dense(units=6, kernel_initializer='uniform', activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Ajouter la couche de sortie avec une unité binaire, et ne pas oublier l'activation sigmoïde fonction à utiliser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajouter la couche de sortie\n",
    "classifier.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Configurer le modèle d'apprentissage, via la méthode de comilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiler le ANN\n",
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Ajouster le modèle et appliquer la validation croisée avec une taille de lot de 10. Répéter 50 ou 100 fois (époque = 50 ou 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajuster le ANN à l'ensemble d'entraînement\n",
    "classifier.fit(X_train, y_train, batch_size=10, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Faire des prédictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédire les résultats sur l'ensemble de test\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Evaluer le modèle à l'aide de la matrice de confusion et du rapport de classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice de confusion et rapport de classification\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Prédire si le client avec les informations suivantes quittera la banque ou non : Géographie : France • Pointage de crédit : 600 • Sexe : Homme • Âge : 40 • Ancienneté : 3 • Solde : 60000 • Nombre de produits : 2 • Possède un crédit carte : Oui • Est membre actif : Oui • Salaire estimé : 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple de données client\n",
    "new_customer = [[600, 40, 3, 60000, 2, 1, 1, 50000, 1, 0, 0]]  # Ajouter des variables dummy pour 'Geography' et 'Gender'\n",
    "new_customer = scaler.transform(new_customer)\n",
    "new_prediction = classifier.predict(new_customer)\n",
    "new_prediction = (new_prediction > 0.5)\n",
    "print(new_prediction)  # True pour quitter, False pour rester\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Utiliser des modèles Keras séquentiels dans le cadre du flux de trvail Scikit-Learn via le wrappers trouvés dans la bibliothèque Keras. Suivre les instruction données dans le notebook Python pour comprendre comment utiliser KerasClassifier à partir de keras.wrappers.scikit_learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier():\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(units=6, kernel_initializer='uniform', activation='relu', input_dim=X_train.shape[1]))\n",
    "    classifier.add(Dense(units=6, kernel_initializer='uniform', activation='relu'))\n",
    "    classifier.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "    classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return classifier\n",
    "\n",
    "classifier = KerasClassifier(build_fn=build_classifier, batch_size=10, epochs=100)\n",
    "accuracies = cross_val_score(estimator=classifier, X=X_train, y=y_train, cv=10, n_jobs=-1)\n",
    "mean_accuracy = accuracies.mean()\n",
    "variance = accuracies.std()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.11 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
